{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae983998",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c41844",
   "metadata": {},
   "source": [
    "### AM41UD - Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8386c97",
   "metadata": {},
   "source": [
    "### PRANAV THIAGARAJAN UMAPATHY - 220366757"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b2559",
   "metadata": {},
   "source": [
    "## Part - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f20a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from scipy.stats import mode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0837ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data from the .txt file\n",
    "train_dt = pd.read_csv(\"UD_Train.txt\", sep=\",\", header=None, names=[\"User\", \"Product\", \"Rating\"])\n",
    "test_dt = pd.read_csv(\"UD_Test.txt\", sep=\",\", header=None, names=[\"User\", \"Product\", \"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre-processing on train data\n",
    "train_dt['User'] = train_dt['User'].str.replace(r'\\(User', '', regex=True)\n",
    "train_dt['Product'] = train_dt['Product'].str.replace(r'Product', '', regex=True)\n",
    "train_dt['Rating'] = train_dt['Rating'].str.replace(r'Rating', '', regex=True)\n",
    "train_dt['Rating'] = train_dt['Rating'].str.replace(r'\\)', '', regex=True)\n",
    "\n",
    "train_dt['User'] = train_dt['User'].astype(int)\n",
    "train_dt['Product'] = train_dt['Product'].astype(int)\n",
    "train_dt['Rating'] = train_dt['Rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data pre-processing on test data\n",
    "test_dt['User'] = test_dt['User'].str.replace(r'\\(User', '', regex=True)\n",
    "test_dt['Product'] = test_dt['Product'].str.replace(r'Product test', '', regex=True)\n",
    "test_dt['Rating'] = test_dt['Rating'].str.replace(r'Rating', '', regex=True)\n",
    "test_dt['Rating'] = test_dt['Rating'].str.replace(r'\\)', '', regex=True)\n",
    "\n",
    "test_dt['User'] = test_dt['User'].astype(int)\n",
    "test_dt['Product'] = test_dt['Product'].astype(int)\n",
    "test_dt['Rating'] = test_dt['Rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc574af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the total number of users and products \n",
    "total_users = train_dt[\"User\"].nunique()\n",
    "total_products = train_dt[\"Product\"].nunique()\n",
    "\n",
    "#printing the results\n",
    "print(\"Number of users:\", total_users)\n",
    "print(\"Number of products:\", total_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivoting the data to create the 'y' dataframe\n",
    "y = train_dt.pivot(index='User', columns='Product', values='Rating')\n",
    "\n",
    "#dimensions of 'y'\n",
    "num_users = y.shape[0]\n",
    "num_products = y.shape[1]\n",
    "\n",
    "#print the results\n",
    "print(\"Dimensions of y: \", y.shape)\n",
    "print(\"Number of users: \", num_users)\n",
    "print(\"Number of products: \", num_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the average rating of each product\n",
    "average_ratings = train_dt.groupby('Product')['Rating'].mean()\n",
    "\n",
    "#histogram of average ratings\n",
    "plt.hist(average_ratings, bins=10,color='teal', edgecolor='black')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram - Average Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b025dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the average rating of each product\n",
    "average_ratings = train_dt.groupby('Product')['Rating'].mean()\n",
    "\n",
    "#sort the average ratings in ascending order & select the top 5 products\n",
    "worst_products = average_ratings.sort_values(ascending=True).head(5)\n",
    "\n",
    "#print the worst products\n",
    "print(\"The 5 worst products:\")\n",
    "print(worst_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31eeef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the average rating given by each user\n",
    "average_ratings = train_dt.groupby('User')['Rating'].mean()\n",
    "\n",
    "#histogram of average ratings\n",
    "plt.hist(average_ratings, bins=10,color='teal', edgecolor='black')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram - Average Ratings by User')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the average rating given by each user\n",
    "average_ratings = train_dt.groupby('User')['Rating'].mean()\n",
    "\n",
    "#sort the average ratings in descending order & select the top 5 users\n",
    "most_generous_users = average_ratings.sort_values(ascending=False).head(5)\n",
    "\n",
    "#print the 5 most generous users based on avg. rating\n",
    "print(\"The 5 most generous users:\")\n",
    "print(most_generous_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the total number of users and products \n",
    "total_users = test_dt[\"User\"].nunique()\n",
    "total_products = test_dt[\"Product\"].nunique()\n",
    "\n",
    "#printing the results\n",
    "print(\"Number of users:\", total_users)\n",
    "print(\"Number of products:\", total_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot the data to create the 'X' dataframe\n",
    "X = test_dt.pivot(index='User', columns='Product', values='Rating')\n",
    "\n",
    "#dimensions of 'X'\n",
    "num_users = X.shape[0]\n",
    "num_products = X.shape[1]\n",
    "\n",
    "#print the results\n",
    "print(\"Dimensions of X: \", X.shape)\n",
    "print(\"Number of users: \", num_users)\n",
    "print(\"Number of products: \", num_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionaries to store the distances between products and top 5 similar products\n",
    "product_distances = {}\n",
    "top_similar_products = {}\n",
    "top_similar_products_with_scores_1={}\n",
    "\n",
    "#iterating each product in the test data\n",
    "for test_product in test_dt[\"Product\"].unique():\n",
    "    distances = {}\n",
    "    test_ratings = test_dt[test_dt[\"Product\"] == test_product].set_index(\"User\")[\"Rating\"]\n",
    "    \n",
    "    #iterating each product in the train data\n",
    "    for train_product in train_dt[\"Product\"].unique():\n",
    "        train_ratings = train_dt[train_dt[\"Product\"] == train_product].set_index(\"User\")[\"Rating\"]\n",
    "        \n",
    "        #calculate the distance between the products using the formula\n",
    "        distance = (test_ratings - train_ratings).abs().sum()\n",
    "        distances[train_product] = distance\n",
    "    \n",
    "    #the top 5 most similar products for the current test product\n",
    "    similar_products = sorted(distances, key=distances.get)[:5]\n",
    "    product_distances[test_product] = distances\n",
    "    top_similar_products[test_product] = similar_products\n",
    "    top_similar_products_with_scores_1[test_product] = sorted(distances.items(),key=lambda x:x[1])[:5]\n",
    "\n",
    "#print the top 5 similar products for each test product\n",
    "print(\"Top 5 similar products:\")\n",
    "for test_product, similar_products in top_similar_products.items():\n",
    "    print(\"Test Product:\", test_product, \"-> Similar Products:\", similar_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529946e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_similar_products_with_scores_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4600d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionaries to store the distances between products and top 5 similar products\n",
    "product_distances = {}\n",
    "top_similar_products = {}\n",
    "top_similar_products_with_scores_2 = {}\n",
    "\n",
    "#iterating over each product in the test data\n",
    "for test_product in test_dt[\"Product\"].unique():\n",
    "    distances = {}\n",
    "    test_ratings = test_dt[test_dt[\"Product\"] == test_product].set_index(\"User\")[\"Rating\"]\n",
    "    \n",
    "    #iterating each product in the train data\n",
    "    for train_product in train_dt[\"Product\"].unique():\n",
    "        train_ratings = train_dt[train_dt[\"Product\"] == train_product].set_index(\"User\")[\"Rating\"]\n",
    "        \n",
    "        #calculate the distance between the products using the Euclidean method\n",
    "        distance = np.sqrt(((test_ratings - train_ratings) ** 2).sum())\n",
    "        distances[train_product] = distance\n",
    "    \n",
    "    #the top 5 most similar products for the current test product\n",
    "    similar_products = sorted(distances, key=distances.get)[:5]\n",
    "    product_distances[test_product] = distances\n",
    "    top_similar_products[test_product] = similar_products\n",
    "    top_similar_products_with_scores_2[test_product] = sorted(distances.items(), key=lambda x: x[1])[:5]\n",
    "\n",
    "#print the top 5 similar products for each test product\n",
    "print(\"Top 5 similar products:\")\n",
    "for test_product, similar_products in top_similar_products.items():\n",
    "    print(\"Test Product:\", test_product, \"-> Similar Products:\", similar_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5018674",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_similar_products_with_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data from the given file\n",
    "churn_df = pd.read_csv(\"Group 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b457b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "churn_df.columns #display the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.head()  #display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.shape  #display the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e71ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.info()  #display information about the columns, data types, and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.describe()  #statistical summary of the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.isna().sum() #null count in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.isna().any() #check null in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc111d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted columns\n",
    "churn_df.drop(churn_df.columns[churn_df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "# churn_df.drop(churn_df.columns[churn_df.columns.str.contains('customer_id',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "churn_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544921ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted characters from Class column\n",
    "churn_df['Class'] = churn_df['Class'].str.replace(r'Churn=', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the special characters in a column\n",
    "churn_df['Class'] = churn_df['Class'].replace({'Y$e$s$$': 'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values from class column\n",
    "churn_df = churn_df.dropna(subset=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932fe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill no-reply in survey column by taking mode\n",
    "mod_value = mode(pd.to_numeric(churn_df['survey'], errors='coerce')).mode[0]\n",
    "churn_df['survey'] = churn_df['survey'].replace('No reply', np.nan).fillna(mod_value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2bc9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill unknown in dependent column by taking median\n",
    "#converting non-numeric values to NaN\n",
    "churn_df['dependents'] = pd.to_numeric(churn_df['dependents'], errors='coerce')\n",
    "#calculating the median excluding NaN values\n",
    "med_value = np.nanmedian(churn_df['dependents'])\n",
    "#fill unknown values with the median\n",
    "churn_df['dependents'] = churn_df['dependents'].fillna(med_value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove -ve sign and round the values in tenure\n",
    "churn_df['Tenure'] = churn_df['Tenure'].apply(lambda x: abs(x)).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb33816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill monthly cost column based on each package value\n",
    "churn_df['monthly_cost'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill monthly cost column based on package prices given\n",
    "churn_df['monthly_cost'] = np.where(churn_df['package'] == 1, '26', \n",
    "                            np.where(churn_df['package'] == 2, '34', \n",
    "                                     np.where(churn_df['package'] == 3, '40', '50'))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column total_cost\n",
    "churn_df['total_cost'] = churn_df['monthly_cost'] * churn_df['Tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arranging the columns before implementing models\n",
    "churn_df = churn_df[['gender', 'location','partner','dependents','senior','Tenure','monthly_cost'\n",
    "                     ,'package','survey','total_cost','Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11774994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a report of the dataframe\n",
    "def report(churn_df):\n",
    "    col = []\n",
    "    d_type = []\n",
    "    uniques = []\n",
    "    n_uniques = []\n",
    "    \n",
    "    for i in churn_df.columns:\n",
    "        col.append(i)\n",
    "        d_type.append(churn_df[i].dtypes)\n",
    "        uniques.append(churn_df[i].unique()[:5])\n",
    "        n_uniques.append(churn_df[i].nunique())\n",
    "    \n",
    "    return pd.DataFrame({'Columns': col, 'data_type': d_type, 'unique_samples': uniques, 'n_uniques': n_uniques})\n",
    "report(churn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histograms of numerical features\n",
    "churn_df.hist(figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#create a correlation matrix heatmap\n",
    "#subset of columns for correlation matrix\n",
    "colm_subset = ['Tenure', 'monthly_cost', 'total_cost','dependents']\n",
    "corr_matrix = churn_df[colm_subset].corr()\n",
    "# Create the correlation matrix heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the DataFrame to avoid modifying the original data\n",
    "churn_df_1 = churn_df.copy()\n",
    "\n",
    "#mapping 1 to \"Male\" and 0 to \"Female\" in the 'gender' column\n",
    "# churn_df_1['gender'] = churn_df_1['gender'].map({1: 'Male', 0: 'Female'})\n",
    "\n",
    "by_gender = churn_df_1.groupby('Class')['gender'].value_counts().to_frame().rename(columns={'gender': 'Freq'}).reset_index().sort_values('Class')\n",
    "\n",
    "#sorting data\n",
    "group_names = churn_df_1['Class'].value_counts().index\n",
    "group_size = churn_df_1['Class'].value_counts()\n",
    "subgroup_names = by_gender['gender']\n",
    "subgroup_size = by_gender['Freq']\n",
    "\n",
    "#assigning colors for the pie chart\n",
    "a, b = [plt.cm.Blues, plt.cm.Reds]\n",
    "\n",
    "#first Ring (outside)\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Churn by Gender')\n",
    "ax.axis('equal')\n",
    "mypie, _ = ax.pie(group_size, radius=1.3, labels=group_names, colors=[a(0.6), b(0.6)])\n",
    "plt.setp(mypie, width=0.3, edgecolor='white')\n",
    "\n",
    "#second Ring (Inside)\n",
    "mypie2, _ = ax.pie(subgroup_size, radius=1.3 - 0.3, labels=subgroup_names, labeldistance=0.7, colors=[a(0.5), a(0.4), b(0.5), b(0.4)])\n",
    "plt.setp(mypie2, width=0.4, edgecolor='white')\n",
    "plt.margins(0, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c010d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Monthly Charge distribution')\n",
    "sns.distplot(churn_df_1[churn_df_1['Class'] == 'Yes']['monthly_cost'], label='Churn')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Monthly Charge distribution Split by Gender')\n",
    "sns.distplot(churn_df_1[(churn_df_1['Class'] == 'Yes') & (churn_df_1['gender'] == 'Male')]['monthly_cost'], label='Male')\n",
    "sns.distplot(churn_df_1[(churn_df_1['Class'] == 'Yes') & (churn_df_1['gender'] == 'Female')]['monthly_cost'], label='Female')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Monthly Charge distribution')\n",
    "sns.distplot(churn_df_1[churn_df_1['Class'] == 'Yes']['monthly_cost'], label='Churn')\n",
    "sns.distplot(churn_df_1[churn_df_1['Class'] == 'No']['monthly_cost'], label='Retain')\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot categorical feature analysis\n",
    "categorical_features = ['gender', 'partner', 'dependents', 'survey', 'package']\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='Class', data=churn_df)\n",
    "    plt.title(f'{feature} vs. Churn')\n",
    "    plt.legend(title='Class', loc='upper right', labels=['No', 'Yes'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ca238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "import shap\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9788c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "churn_df['gender'] = label_encoder.fit_transform(churn_df['gender'])\n",
    "churn_df['location'] = label_encoder.fit_transform(churn_df['location'])\n",
    "churn_df['partner'] = label_encoder.fit_transform(churn_df['partner'])\n",
    "churn_df['dependents'] = label_encoder.fit_transform(churn_df['dependents'])\n",
    "churn_df['package'] = label_encoder.fit_transform(churn_df['package'])\n",
    "churn_df['survey'] = label_encoder.fit_transform(churn_df['survey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting the dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the required columns\n",
    "columns = ['gender', 'location', 'partner', 'dependents', 'senior', 'Tenure', 'monthly_cost',\n",
    "           'package', 'survey', 'total_cost']\n",
    "X = churn_df[columns]\n",
    "y = churn_df['Class']\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)\n",
    "\n",
    "#the shape of train and test sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Implementing statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c59dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing Decision Tree Classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "#evaluating the model\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#calculating Cohen's Kappa\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa Score:\", cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#train the model on the training data\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "#predict on the test data\n",
    "y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "#calculating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#print the classification report\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#calculating Cohen's Kappa\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa Score:\", cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c488c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the logistic regression model\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "#train the model on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "#predict on the test data\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "#calculating the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic regression Classifier:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#calculating Cohen's Kappa\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa Score:\", cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c493f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the target variable into numerical format for XGBoost\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "#train the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "#making predictions on the test set\n",
    "y_pred_encoded = xgb_classifier.predict(X_test)\n",
    "\n",
    "#decode the predicted labels back to string format\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "#evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#calculating Cohen's kappa\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa:\", cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02853af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36036d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "}\n",
    "\n",
    "#initializing the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "#hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(xgb_classifier, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "#train the XGBoost classifier with the best hyperparameters\n",
    "xgb_classifier_best = XGBClassifier(**best_params, random_state=42)\n",
    "xgb_classifier_best.fit(X_train, y_train_encoded)\n",
    "\n",
    "#making predictions on the test set\n",
    "y_pred_encoded = xgb_classifier_best.predict(X_test)\n",
    "\n",
    "#decode the predicted labels back to string format\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "#evaluating the model with the best hyperparameters\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#calculate Cohen's kappa\n",
    "cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa:\", cohen_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable into numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "#creating the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "#training the XGBoost classifier on the full feature set\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "#show feature importances from the trained XGBoost model\n",
    "feature_importances = xgb_classifier.feature_importances_\n",
    "\n",
    "#creating a DataFrame to store feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "#sorting the DataFrame by feature importances in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#print the top 'num_features_to_keep' features based on importance\n",
    "num_features_to_keep = 5\n",
    "selected_features_xgb = feature_importance_df.head(num_features_to_keep)['Feature'].values\n",
    "print(\"Important Features:\", selected_features_xgb)\n",
    "\n",
    "# Keep only the selected features in the training and test datasets\n",
    "X_train_selected = X_train[selected_features_xgb]\n",
    "X_test_selected = X_test[selected_features_xgb]\n",
    "\n",
    "# Initialize a new XGBoost classifier with the selected features\n",
    "xgb_classifier_selected = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the new XGBoost classifier on the selected feature set\n",
    "xgb_classifier_selected.fit(X_train_selected, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set using the new classifier\n",
    "y_pred_encoded = xgb_classifier_selected.predict(X_test_selected)\n",
    "\n",
    "# Decode the predicted labels back to string format\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate the model with the selected features\n",
    "accuracy_selected = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy with Selected Features:\", accuracy_selected)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate Cohen's kappa with the selected features\n",
    "cohen_kappa_selected = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Cohen's Kappa with Selected Features:\", cohen_kappa_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importances from the trained XGBoost model\n",
    "feature_importances = xgb_classifier.feature_importances_\n",
    "\n",
    "#creating a DataFrame to store feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "#sorting the DataFrame by feature importances in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#print the most important feature\n",
    "most_important_feature = feature_importance_df.iloc[0]['Feature']\n",
    "print(\"Most Important Feature:\", most_important_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable into numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "#creating the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "#training the XGBoost classifier on the full feature set\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "#creating a DataFrame to store feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': xgb_classifier.feature_importances_})\n",
    "\n",
    "#sorting the DataFrame by feature importances in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#print feature importances\n",
    "print(\"Feature Importance & Scores:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "#initializing the SHAP (SHapley Additive exPlanations) explainer object\n",
    "explainer = shap.Explainer(xgb_classifier)\n",
    "\n",
    "#calculating SHAP values for the entire test dataset\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "#summary plot showing the overall feature importance based on SHAP values\n",
    "shap.summary_plot(shap_values, X_test, plot_type='dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
